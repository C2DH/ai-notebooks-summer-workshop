{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dea52bdf",
   "metadata": {},
   "source": [
    "# README: expectations for scenarios 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897a6d3e",
   "metadata": {},
   "source": [
    "Use LLMs to explain code for a single Jupyter Notebook **cell** and, if possible, suggest what can be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0459762f",
   "metadata": {},
   "source": [
    "### Requirements: \n",
    "- The code should be in Python.\n",
    "- The explaination shoud take into account the code's context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfe7672",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a71d1c1",
   "metadata": {},
   "source": [
    "## Get the sample notebook's content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ba1244",
   "metadata": {},
   "source": [
    "We will use one of the demo notebook of google colab as an example. We have a copy in ththis repo `examples` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32f70c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['# Digital history of representations: analysing identity and nationalism in the *Capuchin Annual* periodical (1930-1977)']\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "raw_ipynb_url = 'https://raw.githubusercontent.com/C2DH/ai-notebooks-summer-workshop/master/examples/AI_Workshop_Semantic_Search.ipynb'\n",
    "ipynb_data = requests.get(raw_ipynb_url).json()\n",
    "print(ipynb_data['cells'][0]['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99f9dc0",
   "metadata": {},
   "source": [
    "## Scenario 1: Explain, do your magic!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdab43b",
   "metadata": {},
   "source": [
    "Given the notebook as context, let your LLM explain the following cell's code and suggest improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8169e4-0b4e-40ec-a27f-a04ccf1fc877",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_code = \"\"\"\n",
    "tfidf_vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(stop_words=stop_words)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform([' '.join(tokenize(d)) for d in df['description']])\n",
    "svd = SVD(10)\n",
    "svd.fit(tfidf_matrix)\n",
    "\n",
    "def cosine(a, b):\n",
    "    eps = 1e-8\n",
    "    if type(a) is np.ndarray:\n",
    "        return a.dot(b) / ((np.linalg.norm(a) * np.linalg.norm(b)) + eps)\n",
    "    else:\n",
    "        return a.dot(b) / ((a.norm() * b.norm()) + eps)\n",
    "\n",
    "def tfidf_model(query, document):\n",
    "    query_vector = tfidf_vectorizer.transform([' '.join(tokenize(query, tfidf_vectorizer.get_feature_names()))]).todense()\n",
    "    doc_vector = tfidf_vectorizer.transform([' '.join(tokenize(document, tfidf_vectorizer.get_feature_names()))]).todense()\n",
    "    doc_vector = np.squeeze(np.asarray(doc_vector))\n",
    "    query_vector = np.squeeze(np.asarray(query_vector))\n",
    "    return cosine(query_vector, doc_vector)\n",
    "\n",
    "def lsa_model(query, document):\n",
    "    query = ' '.join(tokenize(query, tfidf_vectorizer.get_feature_names()))\n",
    "    document = ' '.join(tokenize(document, tfidf_vectorizer.get_feature_names()))\n",
    "    query_vector = tfidf_vectorizer.transform([query]).todense()\n",
    "    doc_vector = tfidf_vectorizer.transform([document]).todense()\n",
    "    query_vector = svd.transform(query_vector)\n",
    "    doc_vector = svd.transform(doc_vector)\n",
    "    return cosine(np.squeeze(np.asarray(doc_vector)), np.squeeze(np.asarray(query_vector)))\n",
    "\n",
    "def search(model, query, documents, names = None):\n",
    "    scores = [model(query, document) for document in documents]\n",
    "    ixs = list(reversed(np.argsort(scores)[-10:]))\n",
    "\n",
    "    data = [[scores[i] for i in ixs], [documents[i][:150] for i in ixs]]\n",
    "    if names is not None:\n",
    "        data.append([names[i] for i in ixs])\n",
    "    tabulate(data, header=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c793ed3a",
   "metadata": {},
   "source": [
    "Expected output for scenario 1, using Gemini https://gemini.google.com:\n",
    "\n",
    "### Explanation for advanced users, one paragraph:\n",
    "\n",
    "This code builds a search engine that can utilize either TF-IDF or LSA for document retrieval. It creates TF-IDF vectors for all document descriptions, then allows you to choose between a TF-IDF or LSA search model. Both models preprocess the query, convert it and documents to vectors using the chosen method (TF-IDF or LSA with dimensionality reduction), and calculate cosine similarity to rank documents based on their relevance to the query.\n",
    "\n",
    "\n",
    "### Improvements for advanced users, one paragraph:\n",
    "\n",
    "This code can be improved by enhancing text preprocessing (stemming/lemmatization), tuning model parameters (stop words, n-grams, LSA components), using more advanced ranking algorithms (BM25), and improving result presentation (titles, summaries, keyword highlighting). For scalability with large datasets, consider sparse matrices or optimized indexing. Finally, building a user interface would provide a more interactive search experience.\n",
    "\n",
    "\n",
    "### for a newby user in python\n",
    "\n",
    "This code creates a search engine behind the scenes!\n",
    "\n",
    "It allows you to search through documents using two methods:\n",
    "\n",
    "- Regular Search (TF-IDF): This focuses on keywords in the documents. Imagine searching for \"apple\" and it finds documents with \"apple\" mentioned a lot.\n",
    "\n",
    "- Smarter Search (LSA): This tries to understand the meaning behind words. For beginners, think of synonyms. If you search for \"apple\" it might also find documents with \"fruit\" or \"orchard\" because they are related.\n",
    "\n",
    "The code can be improved by:\n",
    "\n",
    "- Being pickier with words: It can currently remove common words like \"the\" but you might want it to also consider removing words like \"very\" or \"just\".\n",
    "- Understanding words better: Right now, it treats \"apple\" and \"apples\" as different, but ideally it would recognize they mean the same thing.\n",
    "- Ranking results better: Currently, it just picks documents that have similar words. In the future, it could consider other factors like document length or how many times a word appears.\n",
    "- Showing results in a nicer way: Right now, it just shows a score and a bit of the document. In the future, it could show the title, a summary, and highlight the words that matched your search."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
